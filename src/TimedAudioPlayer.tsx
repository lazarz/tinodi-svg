import { useRef, useState } from 'react';
import * as Tone from 'tone';

export interface AudioEvent {
    time: number; // Time in seconds
    action: () => void;
    id: string;
}

interface AudioPlayerProps {
    src: string;
    events: AudioEvent[];
}

const TimedAudioPlayer = ({ src, events }: AudioPlayerProps) => {
    const audioRef = useRef<HTMLAudioElement>(null);
    const [triggeredEvents, setTriggeredEvents] = useState<Set<string>>(new Set());
    const [isRecording, setIsRecording] = useState(false);
    const [audioURL, setAudioURL] = useState(null);
    const mediaRecorderRef = useRef(null);
    const audioChunksRef = useRef([]);

    const startRecording = async () => {
        // 1. Po≈æiadame o pr√≠stup k mikrof√≥nu
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // 2. Vytvor√≠me in≈°tanciu MediaRecorder
        mediaRecorderRef.current = new MediaRecorder(stream);

        // 3. Zbierame d√°ta (chunks), keƒè s√∫ dostupn√©
        mediaRecorderRef.current.ondataavailable = (event) => {
            if (event.data.size > 0) {
                audioChunksRef.current.push(event.data);
            }
        };

        // 4. Po zastaven√≠ vytvor√≠me fin√°lny zvukov√Ω s√∫bor
        mediaRecorderRef.current.onstop = () => {
            const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mpeg' });
            const url = URL.createObjectURL(audioBlob);
            setAudioURL(url);
            audioChunksRef.current = []; // Vyƒçist√≠me buffer
        };

        mediaRecorderRef.current.start();
        setIsRecording(true);
    };

    const stopRecording = () => {
        mediaRecorderRef.current.stop();
        setIsRecording(false);
        // Zastav√≠me v≈°etky stopy mikrof√≥nu (vypne sa kontrolka na notebooku)
        mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
    };
    const handleTimeUpdate = () => {
        if (!audioRef.current) return;

        const currentTime = audioRef.current.currentTime;

        events.forEach((event) => {
            // Trigger if we passed the time AND haven't triggered it yet
            if (currentTime >= event.time && !triggeredEvents.has(event.id)) {
                event.action();

                // Mark as triggered so it doesn't fire 60 times in one second
                setTriggeredEvents((prev) => new Set(prev).add(event.id));
            }
        });
    };

    // Reset events if the audio is restarted or src changes
    const handlePlay = () => {
        if (audioRef.current?.currentTime === 0) {
            setTriggeredEvents(new Set());
        }
    };

    const handleUserClick = () => {
        // audioRef.current.currentTime n√°m povie presn√Ω ƒças v sekund√°ch
        const timestamp = audioRef.current.currentTime;
        console.log("Pou≈æ√≠vateƒæ klikol v ƒçase:", timestamp);

        // Tu m√¥≈æe≈° ulo≈æi≈• ƒças k danej note/objektu
        console.log('time', timestamp);
    };

    const playTone = (freq = 440, duration = 0.5) => {
        // 1. Vytvorenie audio kontextu (mozog oper√°cie)
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

        // 2. Vytvorenie oscil√°tora (zdroj zvuku)
        const oscillator = audioCtx.createOscillator();
        const gainNode = audioCtx.createGain(); // Ovl√°daƒç hlasitosti

        oscillator.type = 'sine'; // Typ vlny: 'sine', 'square', 'sawtooth', 'triangle'
        oscillator.frequency.setValueAtTime(freq, audioCtx.currentTime); // Frekvencia v Hz (440 = komorn√© A)

        // 3. Nastavenie "Fade out" efektu, aby zvuk nepraskal
        gainNode.gain.setValueAtTime(0.5, audioCtx.currentTime);
        gainNode.gain.exponentialRampToValueAtTime(0.0001, audioCtx.currentTime + duration);

        oscillator.connect(gainNode);
        gainNode.connect(audioCtx.destination);

        // 4. ≈†tart a stop
        oscillator.start();
        oscillator.stop(audioCtx.currentTime + duration);
    };

    const playNoteTone = async (note) => {
        // Tone.js potrebuje interakciu pou≈æ√≠vateƒæa na spustenie audio kontextu
        await Tone.start();
// DuoSynth - bohat√Ω zvuk vhodn√Ω pre s√≥lov√© husƒæov√© party
        const synth = new Tone.AMSynth().toDestination();
        synth.triggerAttackRelease(note, "0.2s"); // Zahr√° notu (napr. "C4") v dƒ∫≈æke osminovej noty
    };

    return (
        <div className="p-4 border rounded-lg shadow-sm bg-white">
            <audio
                ref={audioRef}
                src={src}
                controls
                onTimeUpdate={handleTimeUpdate}
                onPlay={handlePlay}
                className="w-full"
                style={{ height: '100px', width: '1200px', border: '1px solid #ccc' }}
            />
            <div className="mt-2 text-sm text-gray-500">
                Events registered: {events.length}
            </div>
            <div style={{ padding: '20px', border: '1px solid #ccc', borderRadius: '10px' }}>
                <h3>Audio Rekord√©r</h3>
                {!isRecording ? (
                    <button onClick={startRecording}>üî¥ Spusti≈• nahr√°vanie</button>
                ) : (
                    <button onClick={stopRecording}>‚èπ Zastavi≈• nahr√°vanie</button>
                )}

                {audioURL && (
                    <div style={{ marginTop: '20px' }}>
                        <h4>Nahr√°vka:</h4>
                        <audio src={audioURL} controls/>
                        <br/>
                        <a href={audioURL} download="nahravka.mp3">Stiahnu≈• s√∫bor</a>
                    </div>
                )}
            </div>
            );
            <button onClick={handleUserClick}> Zaznamenaj cas</button>
            <button onClick={() => playNoteTone("C7")}> Zahraj 440</button>
        </div>
    );
};

export default TimedAudioPlayer;